# Objective
The purpose of this project is to extract English words with a Tokenizer as a way to clean the data and prepare it to train the model.

# Step of work
1. Import Library
2. Import Dataset
3. Seperate word with tokenizer not duplicate in dictionary

# Result
I can seperate word with tokenizer not duplicate in dictionary