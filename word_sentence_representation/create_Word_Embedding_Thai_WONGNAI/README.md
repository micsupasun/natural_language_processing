# Project
custom Word Embedding by Wongnai dataset

# Problem
create custom Word Embedding with the dataset for cut sentence

# Solution
export file our embedding for a cut in other models outside

# Methodology
1. Install Library
2. Import Dataset
3. generate tokenizer, padding, and sequences 
4. create a dictionary for temp all index and word
5. The words are sorted by word, and it is the id of the dictionary of each word
6. Train the model with Keras
7. export file our embedding for a cut in other models outside