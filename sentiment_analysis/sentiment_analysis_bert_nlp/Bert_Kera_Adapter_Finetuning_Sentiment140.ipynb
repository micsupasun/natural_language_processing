{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCpvgG0vwXAZ"
      },
      "source": [
        "#Predicting Text Sentimental Analysis with BERT\n",
        "## Technique: Bert-Keras\n",
        "## Model: Softmax\n",
        "## Data: Sentiment140\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBzNbr4wHEvY"
      },
      "source": [
        "General Concept:\n",
        "\n",
        "\n",
        "*   https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html\n",
        "*   https://github.com/google-research/bert\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsZvic2YxnTz",
        "outputId": "639345bc-734a-45b1-b22d-ef6a68d1d102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6yuJNSVZHcs"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWQGmFF8HcEy"
      },
      "source": [
        "Loading bert-tensorflow library\n",
        "\n",
        "\n",
        "*   https://pypi.org/project/bert-tensorflow/\n",
        "*   https://github.com/google-research/bert\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviywGyWyKsA",
        "outputId": "cc3b77cf-82a0-4d52-ccd6-d6a3b3078491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/16/0f9376af49c6adcfbaf2470a8f500105a74dd803aa54ac0110af445837b5/bert_tensorflow-1.0.4-py2.py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 29.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 21.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61kB 11.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhbGEfwgdEtw"
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQTSVnlelBG0"
      },
      "source": [
        "Save model to Google Cloud Storage: https://github.com/google-research/bert/blob/0a0ea64a3ac1f43ed27d75278b9578708f9febcf/predicting_movie_reviews_with_bert_on_tf_hub.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US_EAnICvP7f",
        "cellView": "both"
      },
      "source": [
        "# OUTPUT_DIR = 'output_bert_softmax_sentiment140'\n",
        "# DO_DELETE = False\n",
        "# USE_BUCKET = True\n",
        "# BUCKET = 'bert-finetune-kobkrit'\n",
        "# if USE_BUCKET:\n",
        "#   OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n",
        "#   from google.colab import auth\n",
        "#   auth.authenticate_user()\n",
        "\n",
        "# if DO_DELETE:\n",
        "#   try:\n",
        "#     tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "#   except:\n",
        "#     # Doesn't matter if the directory didn't exist\n",
        "#     pass\n",
        "# tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "# print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmFYvkylMwXn"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGJNMmJMPmj6"
      },
      "source": [
        "## Sentiment140\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC_w8SRqN0fr"
      },
      "source": [
        "Original Sentiment140 Dataset Download: https://docs.google.com/file/d/0B04GJPshIjmPRnZManQwWEdTZjg/edit\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvViHOSEGVnI",
        "outputId": "f5d09e03-69e8-4fec-9dfa-ebb22e59c59c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!gdown --id \"0B04GJPshIjmPRnZManQwWEdTZjg\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B04GJPshIjmPRnZManQwWEdTZjg\n",
            "To: /content/trainingandtestdata.zip\n",
            "81.4MB [00:00, 99.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrXLmJB5Gklr",
        "outputId": "8e7d7dba-58a1-4975-d5b8-1bb6dab844ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!unzip trainingandtestdata.zip\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  trainingandtestdata.zip\n",
            "  inflating: testdata.manual.2009.06.14.csv  \n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n",
            "sample_data\t\t\ttraining.1600000.processed.noemoticon.csv\n",
            "testdata.manual.2009.06.14.csv\ttrainingandtestdata.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fom_ff20gyy6"
      },
      "source": [
        "all_df = pd.read_csv(\"./training.1600000.processed.noemoticon.csv\", encoding=\"latin-1\")\n",
        "train = all_df.sample(100000)\n",
        "test = all_df.sample(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D-7eFxQ3PUe",
        "outputId": "0a542653-fd2d-49f6-a7f2-d1113a765e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1467810369</th>\n",
              "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
              "      <th>NO_QUERY</th>\n",
              "      <th>_TheSpecialOne_</th>\n",
              "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1582738</th>\n",
              "      <td>4</td>\n",
              "      <td>2190350327</td>\n",
              "      <td>Tue Jun 16 02:28:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>KatyCaptivated</td>\n",
              "      <td>Franz Ferdinand - No you Girls...great song.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1422420</th>\n",
              "      <td>4</td>\n",
              "      <td>2058484312</td>\n",
              "      <td>Sat Jun 06 15:02:04 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>AbbieFletcher_</td>\n",
              "      <td>@samjmoody everyone is saying that they are in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136069</th>\n",
              "      <td>0</td>\n",
              "      <td>1880023562</td>\n",
              "      <td>Thu May 21 23:51:43 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Fluffy_Cupycake</td>\n",
              "      <td>@chris_slater seriously.. i was sitting here w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573617</th>\n",
              "      <td>0</td>\n",
              "      <td>2209940985</td>\n",
              "      <td>Wed Jun 17 10:58:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>lisacat</td>\n",
              "      <td>@PRsarahevans Yes, losing an iPhone is crummy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674253</th>\n",
              "      <td>0</td>\n",
              "      <td>2247733795</td>\n",
              "      <td>Fri Jun 19 19:32:31 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>GenMac</td>\n",
              "      <td>on the floor with Goblin, Zil and me. Not sure...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
              "1582738  4  ...      Franz Ferdinand - No you Girls...great song.                                                                   \n",
              "1422420  4  ...  @samjmoody everyone is saying that they are in...                                                                  \n",
              "136069   0  ...  @chris_slater seriously.. i was sitting here w...                                                                  \n",
              "573617   0  ...  @PRsarahevans Yes, losing an iPhone is crummy ...                                                                  \n",
              "674253   0  ...  on the floor with Goblin, Zil and me. Not sure...                                                                  \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JPRuwFYBbln",
        "outputId": "f44e5478-93e8-4803-b167-ae0ada16183f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZM5SXb_Bd65",
        "outputId": "2d164ca1-6bc8-4f57-96d5-56a27b389e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgDMiNRZ8z8d",
        "outputId": "abf2ecf8-1a6e-4890-87c5-3e50d6f5a033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1467810369</th>\n",
              "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
              "      <th>NO_QUERY</th>\n",
              "      <th>_TheSpecialOne_</th>\n",
              "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>952842</th>\n",
              "      <td>4</td>\n",
              "      <td>1824526548</td>\n",
              "      <td>Sun May 17 01:45:59 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>flahlah</td>\n",
              "      <td>live long &amp;amp; prosper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202232</th>\n",
              "      <td>0</td>\n",
              "      <td>1972076421</td>\n",
              "      <td>Sat May 30 08:30:39 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>TCFS</td>\n",
              "      <td>do you know whats not cool? going to drinks th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1299735</th>\n",
              "      <td>4</td>\n",
              "      <td>2006301750</td>\n",
              "      <td>Tue Jun 02 10:57:59 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mnwin</td>\n",
              "      <td>@michaelcavitt Smart thinking!  I decided to k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1308729</th>\n",
              "      <td>4</td>\n",
              "      <td>2012896551</td>\n",
              "      <td>Tue Jun 02 21:30:07 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Brywv</td>\n",
              "      <td>Just love weddings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364818</th>\n",
              "      <td>4</td>\n",
              "      <td>2049839877</td>\n",
              "      <td>Fri Jun 05 17:35:36 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>geee_geee</td>\n",
              "      <td>Making myself a grilled cheese sandwich.. quic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727080</th>\n",
              "      <td>0</td>\n",
              "      <td>2262740871</td>\n",
              "      <td>Sat Jun 20 23:08:03 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>bookie_17_87</td>\n",
              "      <td>Tonight was awful fighting with the bf and bab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>911925</th>\n",
              "      <td>4</td>\n",
              "      <td>1752123392</td>\n",
              "      <td>Sat May 09 21:06:20 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>sippinslow</td>\n",
              "      <td>ang payat ko na, yes! hoping to go down to my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69773</th>\n",
              "      <td>0</td>\n",
              "      <td>1693423420</td>\n",
              "      <td>Sun May 03 22:30:16 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>DrManhattan_</td>\n",
              "      <td>Those heady times we shared - I miss you alrea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171106</th>\n",
              "      <td>4</td>\n",
              "      <td>1980455739</td>\n",
              "      <td>Sun May 31 06:47:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mandyyjiroux</td>\n",
              "      <td>@kaseypoole thank u ! it means a lot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469766</th>\n",
              "      <td>0</td>\n",
              "      <td>2176282317</td>\n",
              "      <td>Mon Jun 15 03:26:23 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Jemz_ADQ</td>\n",
              "      <td>@Realradiorobin Never got to listen to you thi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
              "952842   4  ...                           live long &amp; prosper                                                                   \n",
              "202232   0  ...  do you know whats not cool? going to drinks th...                                                                  \n",
              "1299735  4  ...  @michaelcavitt Smart thinking!  I decided to k...                                                                  \n",
              "1308729  4  ...                                Just love weddings                                                                   \n",
              "1364818  4  ...  Making myself a grilled cheese sandwich.. quic...                                                                  \n",
              "...     ..  ...                                                ...                                                                  \n",
              "727080   0  ...  Tonight was awful fighting with the bf and bab...                                                                  \n",
              "911925   4  ...  ang payat ko na, yes! hoping to go down to my ...                                                                  \n",
              "69773    0  ...  Those heady times we shared - I miss you alrea...                                                                  \n",
              "1171106  4  ...              @kaseypoole thank u ! it means a lot                                                                   \n",
              "469766   0  ...  @Realradiorobin Never got to listen to you thi...                                                                  \n",
              "\n",
              "[10000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNxFFzxNCLcg"
      },
      "source": [
        "From: https://www.kaggle.com/kazanova/sentiment140\n",
        "\n",
        "The data is a CSV with emoticons removed. Data file format has 6 fields:\n",
        "0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
        "1 - the id of the tweet (2087)\n",
        "2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
        "3 - the query (lyx). If there is no query, then this value is NO_QUERY.\n",
        "4 - the user that tweeted (robotickilldozr)\n",
        "5 - the text of the tweet (Lyx is cool)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJS7_VcFB69x"
      },
      "source": [
        "# clean data\n",
        "test.columns = train.columns = all_df.columns = ['sentiment','id','date','query','userid','text']\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prRQM8pDi8xI",
        "outputId": "a2c66354-ca6f-4629-917b-e2f80bbdbb33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentiment', 'id', 'date', 'query', 'userid', 'text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yL3eOyxRsE9",
        "outputId": "56041809-f7eb-42e2-8a65-0f84b9fb9e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# class + = 50000, class - = 50000\n",
        "train['sentiment'].plot(kind='hist')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fea8663c710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfRnHSz3iSXz"
      },
      "source": [
        "For us, our input data is the 'sentence' column and our label is the 'polarity' column (0, 1 for negative and positive, respecitvely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuMOGwFui4it"
      },
      "source": [
        "DATA_COLUMN = 'text'\n",
        "LABEL_COLUMN = 'sentiment'\n",
        "\n",
        "train['sentiment'] = train.sentiment.astype(int)\n",
        "test['sentiment'] = test.sentiment.astype(int)\n",
        "\n",
        "# the polarity of the tweet (0 = negative,4 = positive)\n",
        "# the polarity of the tweet (0 = negative,1 = positive)\n",
        "# positive is 1 negative is 0\n",
        "train.loc[train.sentiment > 0, 'sentiment'] = 1\n",
        "test.loc[test.sentiment > 0, 'sentiment'] = 1\n",
        "\n",
        "label_list = [0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBcgF1qEJFAu",
        "outputId": "93f9cd65-9465-406a-b027-55605defcbae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "train['sentiment'].plot(kind='hist')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fea86533978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD4CAYAAAAtrdtxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUQElEQVR4nO3df/BldX3f8eeLXRFIRFBWyuySLDabxg3+whXJ2DQqDS6YAG0NhYllwzBsK9hJmkwrpp1iNc7IZCIJHWMkZUegNYC2yjZCtytCnHa6wCKGX8byDULYFWXDIpgQoeC7f9zPksvy/e7e/Xy/93657PMxc+d7zvt8zrmfz/6Y1/dzzrnnpqqQJKnHAYvdAUnS9DJEJEndDBFJUjdDRJLUzRCRJHVbutgdmLQjjjiiVq5cudjdkKSpcfvtt/9lVS2bbdt+FyIrV65k69ati90NSZoaSR6ca5unsyRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktRtrCGS5IEkdyX5epKtrfaqJJuT3Nd+Ht7qSXJpkpkkdyY5bug461r7+5KsG6q/pR1/pu2bcY5HkvR8k5iJvLOq3lRVa9r6hcCNVbUKuLGtA5wMrGqv9cCnYBA6wEXA24DjgYt2BU9rc97QfmvHPxxJ0i6L8Yn104B3tOUrgJuBD7b6lTX4lqwtSQ5LclRru7mqdgIk2QysTXIzcGhVbWn1K4HTgRsmNhJJ2kcrL/zSorzvAx9/z1iOO+6ZSAH/M8ntSda32pFV9XBb/g5wZFteDjw0tO+2VttTfdss9RdIsj7J1iRbd+zYMZ/xSJKGjHsm8veranuS1wCbk/zZ8MaqqiRj/37eqroMuAxgzZo13e/3UvsNQpLma6wzkara3n4+AnyBwTWN77bTVLSfj7Tm24Gjh3Zf0Wp7qq+YpS5JmpCxhUiSH0nyil3LwEnA3cBGYNcdVuuA69ryRuDsdpfWCcDj7bTXJuCkJIe3C+onAZvatieSnNDuyjp76FiSpAkY5+msI4EvtLtulwKfrar/keQ24Nok5wIPAme09tcDpwAzwJPAOQBVtTPJR4HbWruP7LrIDpwPfAY4mMEFdS+qS9IEjS1Equp+4I2z1B8FTpylXsAFcxxrA7BhlvpW4Nh5d1aS1MVPrEuSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6jb2EEmyJMkdSf64rR+T5JYkM0muSXJgq7+8rc+07SuHjvGhVv9mkncP1de22kySC8c9FknS801iJvKrwDeG1i8GLqmqnwAeA85t9XOBx1r9ktaOJKuBM4GfBtYCv9+CaQnwSeBkYDVwVmsrSZqQsYZIkhXAe4D/1NYDvAv4fGtyBXB6Wz6trdO2n9janwZcXVVPVdW3gBng+Paaqar7q+pp4OrWVpI0IeOeifwu8G+AH7b1VwPfq6pn2vo2YHlbXg48BNC2P97aP1ffbZ+56i+QZH2SrUm27tixY75jkiQ1YwuRJL8APFJVt4/rPUZVVZdV1ZqqWrNs2bLF7o4kvWQsHeOx3w6cmuQU4CDgUOD3gMOSLG2zjRXA9tZ+O3A0sC3JUuCVwKND9V2G95mrLkmagLHNRKrqQ1W1oqpWMrgw/pWq+mXgJuC9rdk64Lq2vLGt07Z/paqq1c9sd28dA6wCbgVuA1a1u70ObO+xcVzjkSS90DhnInP5IHB1kt8C7gAub/XLgauSzAA7GYQCVXVPkmuBe4FngAuq6lmAJB8ANgFLgA1Vdc9ERyJJ+7mJhEhV3Qzc3JbvZ3Bn1e5tfgD80hz7fwz42Cz164HrF7CrkqR94CfWJUndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUbaQQSfL6cXdEkjR9Rp2J/H6SW5Ocn+SVY+2RJGlqjBQiVfWzwC8DRwO3J/lskp8fa88kSS96I18Tqar7gH8HfBD4OeDSJH+W5B+Pq3OSpBe3Ua+JvCHJJcA3gHcBv1hVr2vLl4yxf5KkF7FRZyL/Efga8MaquqCqvgZQVd9mMDt5gSQHtesof5rkniT/odWPSXJLkpkk1yQ5sNVf3tZn2vaVQ8f6UKt/M8m7h+prW20myYU9fwCSpH6jhsh7gM9W1d8AJDkgySEAVXXVHPs8Bbyrqt4IvAlYm+QE4GLgkqr6CeAx4NzW/lzgsVa/pLUjyWrgTOCngbUMLvIvSbIE+CRwMrAaOKu1lSRNyKgh8mXg4KH1Q1ptTjXwV231Ze1VDE6Bfb7VrwBOb8untXXa9hOTpNWvrqqnqupbwAxwfHvNVNX9VfU0cHVrK0makFFD5KChQKAtH7K3ndqM4evAI8Bm4M+B71XVM63JNmB5W14OPNSO/wzwOPDq4fpu+8xVn60f65NsTbJ1x44de+u2JGlEo4bIXyc5btdKkrcAf7O3narq2ap6E7CCwczhp7p6OU9VdVlVramqNcuWLVuMLkjSS9LSEdv9GvC5JN8GAvwd4J+O+iZV9b0kNwE/AxyWZGmbbawAtrdm2xl8DmVbkqXAK4FHh+q7DO8zV12SNAGjftjwNgaziPcD/wJ4XVXdvqd9kixLclhbPhj4eQa3CN8EvLc1Wwdc15Y3tnXa9q9UVbX6me3urWOAVcCtwG3Aqna314EMLr5vHGU8kqSFMepMBOCtwMq2z3FJqKor99D+KOCKdhfVAcC1VfXHSe4Frk7yW8AdwOWt/eXAVUlmgJ0MQoGquifJtcC9wDPABVX1LECSDwCbgCXAhqq6Zx/GI0map5FCJMlVwN8Fvg4828oFzBkiVXUn8OZZ6vczuD6ye/0HwC/NcayPAR+bpX49cP3eRyBJGodRZyJrgNXt9JIkScDod2fdzeBiuiRJzxl1JnIEcG+SWxl8Eh2Aqjp1LL2SJE2FUUPkw+PshCRpOo0UIlX1J0l+HFhVVV9uz81aMt6uSZJe7EZ9FPx5DJ5n9elWWg58cVydkiRNh1EvrF8AvB14Ap77gqrXjKtTkqTpMGqIPNWelAtAeyyJt/tK0n5u1BD5kyS/CRzcvlv9c8B/H1+3JEnTYNQQuRDYAdwF/HMGnxKf9RsNJUn7j1Hvzvoh8IftJUkSMPqzs77FLNdAquq1C94jSdLU2JdnZ+1yEIMHJb5q4bsjSZomo36fyKNDr+1V9bvAe8bcN0nSi9yop7OOG1o9gMHMZF++i0SS9BI0ahD8ztDyM8ADwBkL3htJ0lQZ9e6sd467I5Kk6TPq6axf39P2qvrEwnRHkjRN9uXurLcCG9v6LwK3AveNo1OSpOkwaoisAI6rqu8DJPkw8KWqet+4OiZJevEb9bEnRwJPD60/3WqSpP3YqDORK4Fbk3yhrZ8OXDGeLkmSpsWod2d9LMkNwM+20jlVdcf4uiVJmgajns4COAR4oqp+D9iW5Jgx9UmSNCVG/Xrci4APAh9qpZcB/3lcnZIkTYdRZyL/CDgV+GuAqvo28IpxdUqSNB1GDZGnq6poj4NP8iPj65IkaVqMGiLXJvk0cFiS84Av4xdUSdJ+b693ZyUJcA3wU8ATwN8D/n1VbR5z3yRJL3J7DZGqqiTXV9XrAYNDkvScUU9nfS3JW8faE0nS1Bn1E+tvA96X5AEGd2iFwSTlDePqmCTpxW+PM5EkP9YW3w28FngXgyf4/kL7uad9j05yU5J7k9yT5Fdb/VVJNie5r/08vNWT5NIkM0nuHP42xSTrWvv7kqwbqr8lyV1tn0vb9RtJ0oTs7XTWFwGq6kHgE1X14PBrL/s+A/xGVa0GTgAuSLIauBC4sapWATe2dYCTgVXttR74FAxCB7iIwWzoeOCiXcHT2pw3tN/a0YYtSVoIewuR4d/sX7svB66qh6vqa235+8A3gOXAafztwxuvYPAwR1r9yhrYwuB24qMYzII2V9XOqnqMwcX9tW3boVW1pX2G5cqhY0mSJmBvIVJzLO+TJCuBNwO3AEdW1cNt03f420fKLwceGtptW6vtqb5tlvps778+ydYkW3fs2NE7DEnSbvYWIm9M8kSS7wNvaMtPJPl+kidGeYMkPwr8V+DXqup5+wx/Cn6cquqyqlpTVWuWLVs27reTpP3GHu/Oqqol8zl4kpcxCJD/UlX/rZW/m+Soqnq4nZJ6pNW3A0cP7b6i1bYD79itfnOrr5ilvSRpQvblUfD7pN0pdTnwjar6xNCmjcCuO6zWAdcN1c9ud2mdADzeTnttAk5Kcni7oH4SsKlteyLJCe29zh46liRpAkb9nEiPtwP/DLgryddb7TeBjzN4Fte5wIPAGW3b9cApwAzwJHAOQFXtTPJR4LbW7iNVtbMtnw98BjgYuKG9JEkTMrYQqar/xfPv7hp24iztC7hgjmNtADbMUt8KHDuPbkqS5mFsp7MkSS99hogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6jS1EkmxI8kiSu4dqr0qyOcl97efhrZ4klyaZSXJnkuOG9lnX2t+XZN1Q/S1J7mr7XJok4xqLJGl245yJfAZYu1vtQuDGqloF3NjWAU4GVrXXeuBTMAgd4CLgbcDxwEW7gqe1OW9ov93fS5I0ZmMLkar6KrBzt/JpwBVt+Qrg9KH6lTWwBTgsyVHAu4HNVbWzqh4DNgNr27ZDq2pLVRVw5dCxJEkTMulrIkdW1cNt+TvAkW15OfDQULttrban+rZZ6pKkCVq0C+ttBlGTeK8k65NsTbJ1x44dk3hLSdovTDpEvttORdF+PtLq24Gjh9qtaLU91VfMUp9VVV1WVWuqas2yZcvmPQhJ0sCkQ2QjsOsOq3XAdUP1s9tdWicAj7fTXpuAk5Ic3i6onwRsatueSHJCuyvr7KFjSZImZOm4Dpzkj4B3AEck2cbgLquPA9cmORd4EDijNb8eOAWYAZ4EzgGoqp1JPgrc1tp9pKp2Xaw/n8EdYAcDN7SXJGmCxhYiVXXWHJtOnKVtARfMcZwNwIZZ6luBY+fTR0nS/PiJdUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVK3qQ+RJGuTfDPJTJILF7s/krQ/meoQSbIE+CRwMrAaOCvJ6sXtlSTtP6Y6RIDjgZmqur+qngauBk5b5D5J0n5j6WJ3YJ6WAw8NrW8D3rZ7oyTrgfVt9a+SfLPz/Y4A/rJz3265eNLv+DyLMuZFtr+NeX8bL+yHY87F8xrzj8+1YdpDZCRVdRlw2XyPk2RrVa1ZgC5NDcf80re/jRcc80Ka9tNZ24Gjh9ZXtJokaQKmPURuA1YlOSbJgcCZwMZF7pMk7Tem+nRWVT2T5APAJmAJsKGq7hnjW877lNgUcswvffvbeMExL5hU1TiOK0naD0z76SxJ0iIyRCRJ3QyRWeztUSpJXp7kmrb9liQrJ9/LhTPCeH89yb1J7kxyY5I57xmfFqM+LifJP0lSSab+dtBRxpzkjPZ3fU+Sz066jwtthH/bP5bkpiR3tH/fpyxGPxdKkg1JHkly9xzbk+TS9udxZ5Lj5v2mVeVr6MXgAv2fA68FDgT+FFi9W5vzgT9oy2cC1yx2v8c83ncCh7Tl90/zeEcdc2v3CuCrwBZgzWL3ewJ/z6uAO4DD2/prFrvfExjzZcD72/Jq4IHF7vc8x/wPgOOAu+fYfgpwAxDgBOCW+b6nM5EXGuVRKqcBV7TlzwMnJskE+7iQ9jreqrqpqp5sq1sYfB5nmo36uJyPAhcDP5hk58ZklDGfB3yyqh4DqKpHJtzHhTbKmAs4tC2/Evj2BPu34Krqq8DOPTQ5DbiyBrYAhyU5aj7vaYi80GyPUlk+V5uqegZ4HHj1RHq38EYZ77BzGfwmM832OuY2zT+6qr40yY6N0Sh/zz8J/GSS/51kS5K1E+vdeIwy5g8D70uyDbge+JeT6dqi2df/73s11Z8T0WQleR+wBvi5xe7LOCU5APgE8CuL3JVJW8rglNY7GMw2v5rk9VX1vUXt1XidBXymqn4nyc8AVyU5tqp+uNgdmxbORF5olEepPNcmyVIG0+BHJ9K7hTfSo2OS/EPg3wKnVtVTE+rbuOxtzK8AjgVuTvIAg3PHG6f84voof8/bgI1V9f+q6lvA/2UQKtNqlDGfC1wLUFX/BziIwcMZX6oW/FFRhsgLjfIolY3Aurb8XuAr1a5aTaG9jjfJm4FPMwiQaT9PDnsZc1U9XlVHVNXKqlrJ4DrQqVW1dXG6uyBG+Xf9RQazEJIcweD01v2T7OQCG2XMfwGcCJDkdQxCZMdEezlZG4Gz211aJwCPV9XD8zmgp7N2U3M8SiXJR4CtVbURuJzBtHeGwUWsMxevx/Mz4nh/G/hR4HPt/oG/qKpTF63T8zTimF9SRhzzJuCkJPcCzwL/uqqmdYY96ph/A/jDJP+KwUX2X5niXwhJ8kcMfhE4ol3nuQh4GUBV/QGD6z6nADPAk8A5837PKf7zkiQtMk9nSZK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqdv/B+dvOSCjmjdFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V399W0rqNJ-Z"
      },
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "From: https://github.com/google-research/bert/blob/0a0ea64a3ac1f43ed27d75278b9578708f9febcf/predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n",
        "\n",
        "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create  `InputExample`'s using the constructor provided in the BERT library.\n",
        "\n",
        "- `text_a` is the text we want to classify, which in this case, is the `Request` field in our Dataframe.\n",
        "- `text_b` is used if we're training a model to understand the relationship between sentences (i.e. is `text_b` a translation of `text_a`? Is `text_b` an answer to the question asked by `text_a`?). This doesn't apply to our task, so we can leave `text_b` blank.\n",
        "- `label` is the label for our example, i.e. True, False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9gEt5SmM6i6"
      },
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "# convert text to InputExample that generate bert embedding to prepare for each layers\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN],\n",
        "                                                                   text_b = None,\n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
        "                                                                   text_a = x[DATA_COLUMN],\n",
        "                                                                   text_b = None,\n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCZWZtKxObjh"
      },
      "source": [
        "Next, we need to preprocess our data so that it matches the data BERT was trained on. For this, we'll need to do a couple of things (but don't worry--this is also included in the Python library):\n",
        "\n",
        "\n",
        "1. Lowercase our text (if we're using a BERT lowercase model)\n",
        "2. Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\n",
        "3. Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\n",
        "4. Map our words to indexes using a vocab file that BERT provides\n",
        "5. Add special \"CLS\" and \"SEP\" tokens (see the [readme](https://github.com/google-research/bert))\n",
        "6. Append \"index\" and \"segment\" tokens to each input (see the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
        "\n",
        "Happily, we don't have to worry about most of these details.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhJSe0QHNG7U",
        "outputId": "70052cd6-88cc-4edb-a34b-b55b7f3271c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "# load model and use tenserflowhub model\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "\n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4oFkhpZBDKm"
      },
      "source": [
        "Great--we just learned that the BERT model we're using expects lowercase data (that's what stored in tokenization_info[\"do_lower_case\"]) and we also loaded BERT's vocab file. We also created a tokenizer, which breaks words into word pieces:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL5W8gEGRTAf"
      },
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evqIct50dt_r"
      },
      "source": [
        "# BERT Keras Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMWiDtpyQSoU"
      },
      "source": [
        "To start with LSTM, we'll need create our own Keras BERT Layer\n",
        "https://github.com/strongio/keras-bert/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WPIJOOfjhl3"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import optimizers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOm4LGCxdkza"
      },
      "source": [
        "# bert layer that we can use for our keras\n",
        "class BertLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_fine_tune_layers=10,\n",
        "        pooling=\"mean\",\n",
        "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.n_fine_tune_layers = n_fine_tune_layers\n",
        "        self.trainable = True\n",
        "        self.output_size = 768\n",
        "        self.pooling = pooling\n",
        "        self.bert_path = bert_path\n",
        "        if self.pooling not in [\"first\", \"mean\"]:\n",
        "            raise NameError(\n",
        "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
        "            )\n",
        "\n",
        "        super(BertLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.bert = hub.Module(\n",
        "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
        "        )\n",
        "\n",
        "        # Remove unused layers\n",
        "        trainable_vars = self.bert.variables\n",
        "        if self.pooling == \"first\":\n",
        "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
        "            trainable_layers = [\"pooler/dense\"]\n",
        "\n",
        "        elif self.pooling == \"mean\":\n",
        "            trainable_vars = [\n",
        "                var\n",
        "                for var in trainable_vars\n",
        "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
        "            ]\n",
        "            trainable_layers = []\n",
        "        else:\n",
        "            raise NameError(\n",
        "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
        "            )\n",
        "\n",
        "        # Select how many layers to fine tune\n",
        "        for i in range(self.n_fine_tune_layers):\n",
        "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
        "\n",
        "        # Update trainable vars to contain only the specified layers\n",
        "        trainable_vars = [\n",
        "            var\n",
        "            for var in trainable_vars\n",
        "            if any([l in var.name for l in trainable_layers])\n",
        "        ]\n",
        "\n",
        "        # Add to trainable weights\n",
        "        for var in trainable_vars:\n",
        "            self._trainable_weights.append(var)\n",
        "\n",
        "        for var in self.bert.variables:\n",
        "            if var not in self._trainable_weights:\n",
        "                self._non_trainable_weights.append(var)\n",
        "\n",
        "        super(BertLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
        "        input_ids, input_mask, segment_ids = inputs\n",
        "        bert_inputs = dict(\n",
        "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
        "        )\n",
        "        if self.pooling == \"first\":\n",
        "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
        "                \"pooled_output\"\n",
        "            ]\n",
        "        elif self.pooling == \"mean\":\n",
        "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
        "                \"sequence_output\"\n",
        "            ]\n",
        "\n",
        "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
        "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
        "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
        "            input_mask = tf.cast(input_mask, tf.float32)\n",
        "            pooled = masked_reduce_mean(result, input_mask)\n",
        "        else:\n",
        "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
        "\n",
        "        return pooled\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.output_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOhxDhDZgXvA"
      },
      "source": [
        "def build_model(max_seq_length):\n",
        "    # input id, masks, seqment\n",
        "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
        "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
        "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
        "    # get bert input by input id, masks, seqment\n",
        "    bert_inputs = [in_id, in_mask, in_segment]\n",
        "\n",
        "    bert_output = BertLayer(n_fine_tune_layers=1, pooling=\"first\")(bert_inputs)\n",
        "    # Option A.\n",
        "    # dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
        "\n",
        "    # Option B.\n",
        "    # reshape = tf.keras.layers.Reshape((1,768), input_shape=(None,768))(bert_output)\n",
        "    # lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, input_shape=(1, 768)))(reshape)\n",
        "\n",
        "    pred = tf.keras.layers.Dense(2, activation='softmax')(bert_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def initialize_vars(sess):\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    K.set_session(sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AggixsYAgRHQ"
      },
      "source": [
        "train_input_ids = []\n",
        "train_input_masks = []\n",
        "train_segment_ids = []\n",
        "train_label_ids = []\n",
        "\n",
        "for i in range(len(train_features)):\n",
        "  train_input_ids.append(train_features[i].input_ids)\n",
        "  train_input_masks.append(train_features[i].input_mask)\n",
        "  train_segment_ids.append(train_features[i].segment_ids)\n",
        "  train_label_ids.append(train_features[i].label_id)\n",
        "\n",
        "test_input_ids = []\n",
        "test_input_masks = []\n",
        "test_segment_ids = []\n",
        "test_label_ids = []\n",
        "\n",
        "for i in range(len(test_features)):\n",
        "  test_input_ids.append(test_features[i].input_ids)\n",
        "  test_input_masks.append(test_features[i].input_mask)\n",
        "  test_segment_ids.append(test_features[i].segment_ids)\n",
        "  test_label_ids.append(test_features[i].label_id)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWYFcve1_5C6"
      },
      "source": [
        "# Initialize session\n",
        "sess = tf.Session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUhmZmp8nMTZ"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_grxBp8YnRw_"
      },
      "source": [
        "# # Clear and load model\n",
        "# model = None\n",
        "# model = build_model(MAX_SEQ_LENGTH)\n",
        "# initialize_vars(sess)\n",
        "\n",
        "# tf.gfile.Copy(\n",
        "#      OUTPUT_DIR+\"/BertLSTM.h5\",\n",
        "#     \"BertLSTM.h5\",\n",
        "#     overwrite=True\n",
        "# )\n",
        "# model.load_weights('BertLSTM.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0mcGoWMnGfc"
      },
      "source": [
        "# Train Model (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJer9ckmikkV"
      },
      "source": [
        "model = build_model(MAX_SEQ_LENGTH)\n",
        "\n",
        "# Instantiate variables\n",
        "initialize_vars(sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH6goBF4MU-p"
      },
      "source": [
        "model.fit(\n",
        "    [train_input_ids, train_input_masks, train_segment_ids],\n",
        "    train_label_ids,\n",
        "    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_label_ids),\n",
        "    epochs=1,\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYQ8KSMPk6WP"
      },
      "source": [
        "# model.save('BertLSTM.h5')\n",
        "# tf.gfile.Copy(\n",
        "#     \"BertLSTM.h5\",\n",
        "#     OUTPUT_DIR+\"/BertLSTM.h5\",\n",
        "#     overwrite=True\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3K9y76fB8V0"
      },
      "source": [
        "# Test set prediction  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zC5PEz2m2BG"
      },
      "source": [
        "predictions = model.predict([test_input_ids,\n",
        "                            test_input_masks,\n",
        "                            test_segment_ids]\n",
        "                           )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK7xi8t2nexk"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNKvhywoCZ3u"
      },
      "source": [
        "labels = [\"Negative\", \"Positive\"]\n",
        "results = [(sentence, prediction, labels[np.argmax(prediction)]) for sentence, prediction in zip(test[DATA_COLUMN], predictions)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU_4jT35JtrO"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWG5MYfTOi03"
      },
      "source": [
        "labels = [x[2] for x in results]\n",
        "plt.hist(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C11d6pciD6m4"
      },
      "source": [
        "# Prediction on Input Sentence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueKsULteiz1B"
      },
      "source": [
        "Now let's write code to make predictions on new sentences:\n",
        "cite: https://github.com/google-research/bert/issues/322"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-thbodgih_VJ"
      },
      "source": [
        "pred_sentences = [\n",
        "  \"Microsft lost a trillion of dollar, People hate this\",\n",
        "  \"Saudis Race to Restore Oil Output After Aramco Attacks\",\n",
        "  \"Trump Defends Brett Kavanaugh After New Revelations\",\n",
        "  \"Google got double the profit\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsrbTD2EJTVl"
      },
      "source": [
        "def getPrediction(in_sentences):\n",
        "  labels = [\"Negative\", \"Positive\"]\n",
        "\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  input_input_ids = []\n",
        "  input_input_masks = []\n",
        "  input_segment_ids = []\n",
        "\n",
        "  for i in range(len(input_features)):\n",
        "    input_input_ids.append(input_features[i].input_ids)\n",
        "    input_input_masks.append(input_features[i].input_mask)\n",
        "    input_segment_ids.append(input_features[i].segment_ids)\n",
        "\n",
        "  predictions = model.predict([input_input_ids,\n",
        "                            input_input_masks,\n",
        "                            input_segment_ids]\n",
        "                           )\n",
        "\n",
        "  return [(sentence, prediction, labels[np.argmax(prediction)]) for sentence, prediction in zip(in_sentences, predictions)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrZmvZySKQTm"
      },
      "source": [
        "predictions = getPrediction(pred_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXkRiEBUqN3n"
      },
      "source": [
        "Voila! We have a sentiment classifier!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERkTE8-7oQLZ"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPLy0YB9F5j0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}